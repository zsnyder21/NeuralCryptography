# Neural Cryptography

## Motivation
Encryption is a necessity. It protects private/sensitive information or enhances the security of communication between
client applications and servers. There are many different forms of encryption, but fundamentally the idea is to make
sensitive data unintelligible and unusable to an unauthorized viewer. For example, someone gains access to a SQL
database containing user logins and passwords. If the passwords are not encrypted, gaining access to any user's account
just became trivial. If the passwords are encrypted, however, they would still need to be decrypted to gain
access - no easy task!

Another application of encryption  is sending covert information or secret messages. Think the Enigma Game - breaking
the German code was instrumental in the overthrow of the Nazi regime.

Or suppose information needs to be sent to a covert operative - would it be sent in plaintext? Of course not! It would
be encoded in some way. Another level up would be to send an encrypted message to this operative in such a way that an
outside observer wouldn't even be aware that there is a covert message being sent. To achieve this goal, we can embed a
message within an image.

With that in mind, our goal will be to construct a convolutional neural network to encrypt and decrypt information within
an image.

## The Network
### Overview
The idea here is to create a network that encrypts information by combining text with an image and can then separate the
text from the new image to recover the text. Note that all of the text must be tokenized in order for the network to 
properly process it.

<img src="./img/Diagrams/Workflow.png">

The CNN is divided into two parts:
* **Encoder**: This portion of the network takes an image and text and embeds the text within the image
  

* **Decoder**: This segment of the network takes the output of the encoder and extracts the text from it

### Training the Network
To train the network, we use randomly generated images and strings. This helps the network to be robust and work with
a very wide variety of text and images. Examples of random images and text can be seen below

|             Random Image 1              |               Random Image 2             |
|------------------------------|-----------------------------------------------------|
|<img src="./img/Raw/Random1_NoAxes.png"> | <img src="./img/Raw/Random2_NoAxes.png"> |


Note that some characters do not display very well within typical text editors or consoles.
* Random Text 1: +|lIgtNF:'	uNT'tX1lB!Tah9]QV;=Xsfi6Cs#,_#.|#wSW (p"EpY&
G#*L-!vhtj%P[k{O8v`


* Random Text 2: pQ9u>q,zH u77">uTRT#)wFwvw|44&^AWb=&HU#r*ZZ5yWI{^/5.sU},hK2n.7Z
,Q}<w527/&[\="6$&M
  
The general structure of the network is outlined in the following diagram:

<img src="./img/Diagrams/NeuralNetStructure.png">

I trained the network for a variable number of epochs. Sentence reconstruction accuracy quickly plateaued at 100% after
the 2nd epoch. Using a custom threshold Callback in the model, I stopped training when image reconstruction loss reached
0.008. This threshold value was chosen as a trade-off between time and to prevent overfitting.

Final model scores were as follows:

* Sentence Reconstruction Loss: 2.7585e-4


* Image Reconstruction Loss: 0.0078


* Sentence Reconstruction Categorical Accuracy: 100%

## Results
Now that we have a well-trained model, let's try and apply it to something. Take for example this Kip Thorne quote: "A
black hole really is an object with very rich structure, just like Earth has a rich structure of mountains, valleys,
oceans, and so forth. Its warped space whirls around the central singularity like air in a tornado."

We will embed this quote within the following image:

<img src="img/Raw/twister.png">

A little bit of pre-processing is necessary to prepare the image for the network. This pre-processing simply ensures
that the image has the dimensions that the neural network expects: (2000, 2000, 3). That is, a 2000x2000 RGB image.
After pre-processing our image looks like this:

<img src="img/PreProcessed/twister.png">

The filler bar color is chosen to be the average color of the image, so as to not ruin the aesthetics. Note that if the
image were larger, the image would be naively cropped down to size, taking the first 2000 pixels in the appropriate
dimensions.


After feeding this pre-processed image and our chosen text, the network outputs the following image:

<img src="img/Embedded/twister.png">

Those images look nearly identical to me. To put that into quantitative terms, the mean pixel difference is ~0.0071,
nearly imperceptible.


All that's left is to take this image with embedded text and attempt to extract the text from it. Feeding the previous
image into the decoder segment of the network, we obtain the following text:

"A black hole really is an object with very rich structure, just like Earth has a rich structure of mountains, valleys,
oceans, and so forth. Its warped space whirls around the central singularity like air in a tornado."

This is exactly the text we input into the network, demonstrating that we can effectively encode text into an image,
nearly imperceptibly, and with extremely high accuracy decode the text from the image.


## Image Corruption
Say that we have encoded a message of length much smaller than the image size (sentence length around 10% of image size)
and have sent it overseas for someone to decode. Unfortunately, while in transit some of the information has been lost or
corrupted. I've simulated this by replacing random percentages of the pixels within the image with either black, white, 
or random pixels. How well can we reconstruct the message now?

The corrupted images (with 30% of the pixels corrupted) appear as follows: 

|             Corrupted Black              |               Corrupted White           |         Corrupted Random  |
|------------------------------|-----------------------------------------------------|---------------------------------|
|<img src="./img/Corrupted/twisterBlack.png"> | <img src="./img/Corrupted/twisterWhite.png"> | <img src="./img/Corrupted/twisterRandom.png">|

These images are decoded as follows

|       Corrupted Black             |            Corrupted White               |                 Corrupted Random                   |
|-------------------------|-----------------------------|----------------------------|
|A black hole really is an object with very rich structure, just likeƒ∂ Earth has a rich structure of mountains, valƒ∂leeyeÃäs, oceans, and so forth. Its warped space whirs around the central singularƒ∂ity like air in a tornado. |A√óbl≈°≈¶WBac¬îk hole reÀãÀÆƒö≈µa«≤√Ωllyƒá…ö is«©a∆öÀïn objƒóe∆Éct w…¥∆Ø∆üÃÅit√îh ve√Ñ éyJ Àî∆Æric∆§ s≈É∆ï»Öt≈Æructure π, ¬õƒ§¬É≈±≈Ωust{ E{ƒòlƒ®<e Earth h»Ñs a»°ƒî r…µich «ØstrucÀ©¬ïure √¥o√Ü…ºf)√àƒë mount∆πa…Ñ≈ºns, valleys,…±√¨ ocee¬ªyeaens, an≈∂d¬Å≈µ so«ç fortƒì ±h.1«á 4≈πÀõtMÀ§ƒæ√ø¬Å√Ç §≈∂?≈∫√Å à√Æs&#124;«ß ƒ∂Ãé4»ça çƒöƒë¬ë.«Ω øhƒ¢»ï…ëeƒΩdQ»õ ¬º¬òÃá»ó√≥pƒù»∫¬∏a¬Æ êƒé^ƒã¬∑ƒ≤`√å ÆÀ≠ É∆°ƒûe 7≈∏Ãî ¥¬æ√∫»¶≈ºÃû√≠»Æ¬å¬â¬î»ÆÀùÃõ…´:¬æ√≥Ãö»ëiƒç…º ú¬ë«îÀî…Ω≈à»Ø ±Àî¬ë√ã»•4ƒ∂≈æ≈ø∆©∆•…±ƒß»∂…õ…∂…ô+ÀÑs»ì…ÑMr&#124;»âƒøÃöFLr«ë≈§z√ßsuƒï√ån∆∂ÃÇ Ç¬û«®«ô,∆∂sƒ≤¬øO∆¥¬Ö√ëtÀ°¬∏À¨h¬á«ÆU¬Ω À∫∆óÃí√ºƒüT¬õ»™≈àƒ¥«äÀù¬í∆áÀî«ù√õÀΩ«Ö«É≈õ»ïÀØƒæ…∂√ù≈ìÀêÀÉ æ≈µ≈®À•{K∆¥aƒ∂À≠»µ) ∆û√≠»®»≤ƒæÃàn«é»ø«ü3ƒé√ømpg»© ∏«ëÃè≈ßm«Çu»ÜÀülarit≈ûÀÄÃö √†lƒÑ«ôi≈ë√çke«≠ air in Ãä√®a∆ÉtoÀç≈∑rn.ad≈õo.|A black hole really is an object with very rich structure, just like Earth has a ric∆ëh struct∆ìure of \`mountainsee, valleys, oceans, and so fozrthƒµ. IÃà\`Àîts ÀàwaÀîÀ≠≈±»ÑzÀÉ«ä¬û»ÑzÀ≠n…∂»ñƒírp¬ëe»ïd Àîz»ís ©ƒæpa…ñcÀîÀîe…ô»Ñ wƒåhir√øƒålÀ≠»ªsÃé»ï8g«áarÀØ¬∑ouÀînd…õ≈õ«é»Ñth»Ñe…ΩÃÅ«äƒû√•Àî centra-ƒ∂lƒåÀî singularity like air in a tornado.|


We can no longer extract the exact sentence anymore. Though it isn't identical, the essence of the message is still
there, though some of it has been lost due to the corrupt image. To quantify this, the Levenshtein distance (computed by
counting the number of replacements, insertions, or deletions it takes to get from one sentence to the other) is 19. The
Levenshtein ratio for this reconstruction is ~0.953, which is very good!

Below we see plots of both Levenshtein distance and ratio as a function of image corruption. We can see that the ratio
starts to sharply descend as we near 40% image corruption, suggesting that images corrupted beyond this point may not be
able to have text properly decoded via this neural net. The plot of Levenshtein distance also supports this tipping
point. 

These results are unique to black pixels: A black pixel decodes to a null character, and so this doesn't interfere with
our decrypted sentence much. If we use different colored pixels to corrupt our image, however, the Leavenshtein
distances and ratios deviate from readable levels far faster. See below

»Ñ»Ñ»Ñ»Ñ»Ñƒ∂ƒ∂»Ñ»Ñƒ∂»Ñz»Ñ»Ñƒ∂»ÑÀîƒ∂ƒ∂ƒ∂ƒåƒ∂»Ñ»Ñƒåƒ∂ƒ∂ƒ∂»Ñƒ∂ƒåƒ∂ƒ∂Àî»Ñƒ∂ƒåÀî»ÑÀîƒ∂ƒåƒ∂»Ñ»Ñ»Ñ»Ñƒ∂Àî»Ñ»Ñ»ÑÀîƒ∂ƒ∂ƒåƒ∂»Ñƒ∂ƒåƒ∂»Ñ»Ñƒ∂»Ñ»Ñƒ∂ƒ∂»ÑƒåÀîƒ∂ƒ∂»Ñƒ∂ƒ∂ƒ∂ƒ∂»Ñƒ∂»Ñƒ∂Àîƒ∂ƒ∂»Ñƒ∂»ÑÀîƒ∂»Ñ»Ñ»Ñƒ∂»Ñƒåƒ∂ƒ∂»Ñ»Ñ»Ñƒ∂»Ñ»Ñƒ∂ƒ∂»Ñƒ∂ƒ∂ƒ∂»ÑÀîƒ∂Àî»Ñƒ∂ƒ∂ƒ∂»Ñ»Ñƒå»Ñƒ∂»Ñ»Ñƒ∂ƒ∂»Ñƒ∂ƒ∂ƒ∂ƒ∂ƒ∂ƒåƒå»Ñ»Ñ»ÑÀîƒå»Ñ»Ñƒ∂ƒ∂»Ñ»Ñƒå»Ñ»Ñ»Ñƒ∂»Ñƒ∂»Ñƒ∂»Ñ»Ñƒåƒ∂r»Ñƒ∂ƒ∂Àîƒ∂ƒå»Ñƒ∂»Ñƒ∂ƒ∂ƒåƒ∂ƒåƒ∂ƒå»Ñƒ∂ƒ∂Àî»Ñ»Ñ»Ñ»Ñƒ∂»Ñ»Ñƒå»Ñƒ∂ƒ∂ƒ∂ƒåƒ∂»ÑÀîÀîƒå»Ñ»Ñ»Ñ»Ñ»Ñƒ∂»Ñƒ∂ƒå»Ñrƒ∂ƒ∂ƒ∂ƒåƒ∂Àîƒ∂»Ñ»Ñ¬ëƒ∂¬ëƒ∂»Ñ»Ñ»Ñƒ∂»Ñƒå…ñƒ∂ƒ∂,ƒ∂ƒ∂ƒ∂ƒ∂Àî»Ñ»ÑÀî»Ñ»Ñƒ∂ƒ∂»Ñƒ∂ÀîÀ≠Àî»Ñ»Ñƒåƒ∂Àî»Ñzƒ∂ƒ∂»Ñ»Ñƒ∂ƒ∂»Ñƒåƒå»Ñƒ∂»Ñƒ∂ƒåƒ∂»Ñ¬ÇÀî»Ñ»Ñ`»ÑÀî≈±ƒåÀîƒ∂`»∂…Ωƒ∂ƒå»Ñƒ∂ƒ∂»ÑÀî»Ñƒ∂ƒ∂ƒåƒ∂ƒåÀîƒåzzƒ∂»Ñ`…ºƒ∂»Ñ»Ñ»ÑÀî»Ñ»Ñ≈àƒ∂ƒ∂»Ñƒ∂»Ñƒ∂ƒ∂Àî»ÑÀîƒ∂ƒ∂Àî»Ñƒ∂ƒ∂»Ñƒ∂ƒ∂z»Ñƒ∂ƒ∂ƒ∂»Ñƒ∂ƒ∂»Ñ»Ñ»Ñƒ∂»Ñƒ∂»Ñƒ∂ƒå»Ñr»Ñ»Ñ»Ñƒ∂ƒ∂ƒ∂ƒ∂ƒ∂ƒ∂z»Ñ»Ñƒ∂»Ñ»Ñƒ∂z¬∑ƒ∂»Ñƒ∂ƒ∂»Ñƒ∂ƒ∂ƒ∂»ÑÀîƒ∂Àîƒ∂Àîƒ∂ƒ∂≈ã»Ñhƒ∂»Ñƒ∂Àî»Ñ»Ñƒ∂»Ñƒå¬ûzƒ∂»Ñ»Ñ…ñƒ∂∆áƒ∂≈ã»Ñƒ∂ƒåƒ∂ƒ∂»Ñ…ºƒ∂«áƒ∂»Ñƒ∂»ÑÀØƒ∂»Ñƒ∂…ñƒ∂»Ñ»Ñ∆¢ƒ∂ƒ∂»Ñ»Ñ»Ñ`ƒ∂¬∑»Ñƒ∂»Ñƒ∂»Ñƒ∂`ƒ∂Àî»Ñƒ∂ƒ∂ƒ∂ƒ∂ƒ∂¬ëƒ∂»Ñƒ∂ƒå»Ñ»Ñƒå»ÑÀî»Ñ`ƒ∂»ÑÀî»Ñƒ∂ƒ∂ƒ∂ƒ∂`ƒ∂ƒåƒ∂ƒ∂»Ñƒ∂ƒ∂ƒ∂ƒ∂ƒ∂»Ñƒå»ÑÀî,»Ñƒåzƒ∂Àî»Ñƒ∂ƒ∂…ñƒåÀîƒ∂ƒ∂Àîƒ∂ƒ∂ƒ∂ƒ∂ƒ∂≈ãƒ∂ƒ∂Àî¬∑»ÑÀî»∂ƒ∂¬ëÀîƒåÀ¢≈®`¬ëe…ñ ©ƒ∂…∂Àîƒ∂r¬û¬ºÀî…ñƒ∂Àî…ñƒ∂¬∏…ñ«ä»Ñƒ∂…∂zÀ≠ƒ∂`ƒ∂»Ñ»Ñ∆†`ƒ∂z»Ñƒ∂…Ωƒ∂»Ñƒåƒ∂ƒ∂ƒ∂ƒ∂»ÑÀîƒ∂ƒå»Ñ»Ñƒå»Ñ»Ñ»Ñ»Ñ»Ñƒ∂ƒ∂ƒ∂ƒåƒåzƒ∂n»Ñƒ∂»Ñƒ∂ƒ∂»Ñƒ∂ƒ∂ƒ∂ƒ∂ƒå»ÑÀîÀî»Ñƒ∂ƒ∂ƒ∂ƒ∂ƒåÀîƒ∂ƒ∂ƒ∂ƒ∂»Ñƒåƒ∂»Ñ»Ñƒ∂fƒ∂ƒ∂ƒå»Ñƒ∂»Ñƒ∂»Ñ»Ñr»Ñƒ∂»Ñ»Ñ»Ñƒ∂ƒ∂ƒ∂ƒ∂ƒ∂»Ñƒ∂ƒ∂ƒ∂ƒåÀîƒ∂ƒ∂»Ñƒå»Ñ»Ñƒå»Ñƒ∂ƒ∂»Ñ»Ñƒ∂»Ñ»Ñƒ∂ƒ∂»Ñ»Ñ»Ñƒ∂ƒ∂»Ñƒ∂ƒ∂ƒ∂»Ñƒ∂»Ñƒ∂»Ñƒ∂ƒ∂»Ñƒ∂»Ñƒ∂»Ñƒ∂ƒ∂ƒ∂»Ñƒ∂»Ñƒ∂ƒ∂»Ñ»Ñƒ∂ƒ∂ƒ∂ƒ∂»Ñƒ∂»Ñ»Ñ»Ñ»Ñ»Ñ»Ñ»Ñ»Ñƒ∂»Ñƒ∂ƒ∂»Ñƒ∂»Ñƒ∂»Ñ»Ñ»Ñrƒ∂ƒ∂»Ñ»Ñ»Ñƒ∂»Ñ»Ñƒ∂»Ñƒ∂Àîƒ∂ƒ∂»Ñƒ∂»Ñƒåƒ∂ƒ∂»Ñ»Ñƒå»Ñ»Ñ»Ñ»Ñƒ∂ƒ∂ƒ∂»Ñ»Ñƒ∂ƒå»Ñ»Ñƒ∂»Ñ»Ñ»Ñ»Ñ»Ñƒ∂ƒ∂ƒ∂ƒåƒ∂»Ñ»Ñ»Ñ»Ñ»ÑÀîƒ∂»Ñƒ∂»Ñƒ∂»Ñ»Ñƒ∂…ñƒ∂»Ñ»Ñƒ∂ƒ∂»Ñ»Ñƒ∂ƒå»Ñ»Ñ»Ñ»Ñ»Ñ»Ñ»ÑÀîƒåƒ∂ƒ∂ƒ∂ƒ∂ƒ∂»Ñƒ∂ƒåƒ∂ƒ∂ƒ∂r»Ñƒ∂ƒåƒ∂ƒ∂ƒåƒ∂»Ñ»Ñƒ∂ƒ∂ƒåƒ∂»Ñ»Ñ»Ñƒ∂»Ñ»Ñ»Ñƒ∂»Ñƒ∂»Ñƒ∂ƒå»Ñƒå»Ñ»Ñ